---
layout: post
title: Debugging Generative Models with Taylor Swift
author: Paroma Varma and Chris Ré
---

Modern machine learning techniques like deep learning often require large amounts of training data, which are not readily available for all applications. Weak supervision attempts to alleviate this problem by using heuristics and “weak” classifiers to provide noisy training data. Previous work from the lab, data programming, encodes this weak supervision signal with user-defined labeling functions (as part of a generative model) to noisily label unlabeled data. With data programming and other weak supervision methodologies, these issues still remain:

The generative model may be misspecified, which can affect the performance of the discriminative training that follows.

The errors in the generative model do not provide users any intuition about why there were errors and how they can be fixed.

We describe our novel framework Socratic learning, a systematic process that improves the expressiveness of the generative model by using information from the discriminative model.
